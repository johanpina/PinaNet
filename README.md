# üß¨ PinaNet: Deep Learning Transposable Element Annotator

**PinaNet** es una herramienta bioinform√°tica de alto rendimiento basada en **Deep Learning** para la detecci√≥n y anotaci√≥n autom√°tica de Elementos Transponibles (TEs) en secuencias gen√≥micas crudas (FASTA).

El sistema utiliza una arquitectura h√≠brida de √∫ltima generaci√≥n que combina la capacidad de representaci√≥n de **DNABERT-2** (un modelo de lenguaje pre-entrenado en ADN) con redes neuronales recurrentes bidireccionales (**BiLSTM**) para capturar el contexto secuencial y estructural de los TEs.

---

## üöÄ Caracter√≠sticas Principales

* **Arquitectura H√≠brida Avanzada:** Integra DNABERT-2 (para embeddings ricos de k-mers) + BiLSTM (para memoria secuencial) + Clasificador Lineal.
* **3 Niveles de Clasificaci√≥n:**
    * **Binario:** Detecci√≥n de presencia/ausencia (TE vs Background).
    * **Orden:** Clasificaci√≥n taxon√≥mica general (ej. LTR, LINE, SINE, DNA).
    * **Superfamilia:** Clasificaci√≥n taxon√≥mica detallada (ej. Gypsy, Copia, Mutator, etc.).
* **Procesamiento Paralelo Eficiente:** Implementa un patr√≥n Productor-Consumidor donde m√∫ltiples n√∫cleos de CPU tokenizan y preparan el genoma mientras la GPU realiza la inferencia masiva.
* **Sliding Window Inteligente:** Procesa genomas completos de cualquier tama√±o fragment√°ndolos en "chunks" de 50kb con ventanas deslizantes y fusi√≥n autom√°tica de predicciones adyacentes.
* **Salida Est√°ndar:** Genera archivos **GFF3** compatibles con IGV, JBrowse y otros visores gen√≥micos.

---

## üõ†Ô∏è Instalaci√≥n

### 1. Prerrequisitos
* **Python 3.9** o superior.
* (Recomendado) GPU NVIDIA con drivers CUDA instalados para inferencia r√°pida.
* Git.

### 2. Clonar el Repositorio
```bash
git clone https://github.com/TU_USUARIO/PinaNet.git
cd PinaNet
```

### 3. Crear Entorno Virtual
Se recomienda aislar las dependencias para evitar conflictos:

```bash
# Crear entorno
python -m venv venv

# Activar en Linux/Mac
source venv/bin/activate

# Activar en Windows
.\venv\Scripts\activate
```

### 4. Instalar Dependencias
```bash
pip install -r requirements.txt
```
*(Aseg√∫rese de que `torch`, `transformers`, `biopython`, `typer`, `pandas`, `numpy` y `tqdm` est√©n instalados).*

---

## üìÇ Configuraci√≥n de Modelos

Debido al gran tama√±o de los pesos neuronales, los modelos entrenados **no se incluyen** en el control de versiones de Git. Debes copiar tus carpetas directamente de los archivos del servidor o solicitarlos al owner del proyecto.

La estructura de carpetas debe verse **exactamente** as√≠ para que el software los reconozca:

```text
PinaNet/
‚îú‚îÄ‚îÄ Te_annotator.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ binary/            <-- Archivos del modelo Binario
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ order/             <-- Archivos del modelo de Orden
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ superfamilies/     <-- Archivos del modelo de Superfamilia
‚îÇ       ‚îú‚îÄ‚îÄ config.json
‚îÇ       ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
```

**Nota Importante:** Aseg√∫rate de que cada carpeta contenga, como m√≠nimo, el archivo de configuraci√≥n `config.json` y los pesos del modelo `pytorch_model.bin`.

---

## üíª Uso

El programa se ejecuta desde la l√≠nea de comandos (CLI). La sintaxis b√°sica es:

```bash
python Te_annotator.py [ARGUMENTOS] [OPCIONES]
```

### Argumentos Principales

| Argumento | Descripci√≥n | Requerido |
| :--- | :--- | :---: |
| `fasta_file` | Ruta al archivo de entrada (`.fasta`, `.fa`, `.fna`). | ‚úÖ |
| `output_gff` | Ruta donde se guardar√° el archivo de anotaci√≥n (`.gff3`). | ‚úÖ |

### Opciones y Par√°metros

| Opci√≥n | Comando | Descripci√≥n | Default |
| :--- | :--- | :--- | :--- |
| **Nivel** | `--level` | Nivel de clasificaci√≥n. Valores aceptados: `binary`, `order`, `superfamilies`. | `binary` |
| **Workers** | `--num-workers` | N√∫mero de n√∫cleos de CPU para la tokenizaci√≥n en paralelo. | `4` |
| **Device** | `--device` | Dispositivo de ejecuci√≥n: `cuda` (GPU) o `cpu`. | `cuda` |

---

## üß™ Ejemplos de Ejecuci√≥n

### 1. Detecci√≥n Binaria (TE vs No-TE)
Escanea el genoma y marca regiones que contienen elementos transponibles sin clasificarlos. √ötil para enmascaramiento r√°pido o detecci√≥n de densidad.

```bash
python Te_annotator.py \
    ./test/genoma_maiz.fasta \
    ./resultados/deteccion_binaria.gff3 \
    --level binary \
    --num-workers 8 \
    --device cuda
```

### 2. Clasificaci√≥n por √ìrdenes
Clasifica los elementos encontrados en grandes grupos taxon√≥micos (LTR, LINE, TIR, etc.).

```bash
python Te_annotator.py \
    ./test/genoma_arroz.fasta \
    ./resultados/clasificacion_ordenes.gff3 \
    --level order \
    --device cuda
```

### 3. Clasificaci√≥n Fina (Superfamilias)
El an√°lisis m√°s detallado. Clasifica en familias espec√≠ficas (Gypsy, Copia, etc.).

```bash
python Te_annotator.py \
    ./test/genoma_desconocido.fasta \
    ./resultados/full_annotation.gff3 \
    --level superfamilies \
    --num-workers 4
```

---

## üìä Formato de Salida (GFF3)

El archivo generado sigue el est√°ndar **GFF3** (Generic Feature Format versi√≥n 3). Ejemplo de salida:

```gff
##gff-version 3
chr1	DNABERT2	LTR	10500	12400	.	+	.	ID=LTR_10500_12400;Name=LTR_prediction
chr1	DNABERT2	LINE	15000	15800	.	+	.	ID=LINE_15000_15800;Name=LINE_prediction
```

* **Columna 1 (SeqID):** ID de la secuencia (cromosoma/contig).
* **Columna 2 (Source):** Fuente (`DNABERT2`).
* **Columna 3 (Type):** Tipo de TE (Predicci√≥n del modelo, ej. `LTR`).
* **Columna 4-5 (Start-End):** Coordenadas 1-based.
* **Columna 9 (Attributes):** ID √∫nico y metadatos para visualizaci√≥n.

---

## ‚öôÔ∏è Arquitectura del Sistema

PinaNet resuelve el problema de la longitud de entrada limitada de los modelos tipo BERT mediante una estrategia de **"Divide y Vencer√°s"**:

1.  **Chunking:** El genoma se divide en fragmentos manejables de 50kbp (lazy loading).
2.  **Sliding Window:** Cada fragmento se subdivide en ventanas de 512 tokens con un solapamiento (*stride*) de 128 tokens para evitar p√©rdida de informaci√≥n en los bordes.
3.  **Inferencia H√≠brida:**
    * **DNABERT-2:** Extrae caracter√≠sticas profundas de la secuencia de ADN.
    * **BiLSTM:** Analiza la secuencia de caracter√≠sticas en ambas direcciones para entender el contexto estructural.
4.  **Fusi√≥n:** Las predicciones de las ventanas se proyectan a coordenadas globales y los fragmentos adyacentes de la misma clase se fusionan en una sola anotaci√≥n continua.

---

## ‚ö†Ô∏è Soluci√≥n de Problemas Comunes

* **Error `CUDA Out of memory`:** El modelo es grande. Intenta reducir los trabajadores (`--num-workers 0`) para liberar RAM del sistema o asegura que ninguna otra aplicaci√≥n use la VRAM. El *batch size* interno est√° optimizado a 1 (lo que equivale a procesar ~150 ventanas de 512bp en paralelo por cada chunk de 50kb).
* **Error `Model not found`:** Verifica que hayas copiado las carpetas `binary`, `order` y `superfamilies` dentro de la carpeta `models/` y que los nombres coincidan exactamente.
* **Advertencias de `Triton / Flash Attention`:** Son normales si no tienes la arquitectura de GPU m√°s reciente (Hopper/Ampere). El sistema est√° configurado para cambiar autom√°ticamente a una implementaci√≥n compatible (PyTorch nativo).

---

## üìù Licencia


---
**Desarrollado por Johan S. Pi√±a - 2025**